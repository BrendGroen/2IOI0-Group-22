{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file we train a XGboost model on our data on the BPI_Challenge_2012 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from aux_functions import split_data\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org:resource</th>\n",
       "      <th>lifecycle:transition</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>case:REG_DATE</th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>case:AMOUNT_REQ</th>\n",
       "      <th>position</th>\n",
       "      <th>next_concept:name</th>\n",
       "      <th>next_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2011-10-01 00:38:44.546000+00:00</td>\n",
       "      <td>2011-10-01 00:38:44.546000+00:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>2011-10-01 00:38:44.880000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>2011-10-01 00:38:44.880000+00:00</td>\n",
       "      <td>2011-10-01 00:38:44.546000+00:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "      <td>2011-10-01 00:39:37.906000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "      <td>2011-10-01 00:39:37.906000+00:00</td>\n",
       "      <td>2011-10-01 00:38:44.546000+00:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>20000</td>\n",
       "      <td>3</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011-10-01 00:39:38.875000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>112.0</td>\n",
       "      <td>SCHEDULE</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011-10-01 00:39:38.875000+00:00</td>\n",
       "      <td>2011-10-01 00:38:44.546000+00:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>20000</td>\n",
       "      <td>4</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011-10-01 11:36:46.437000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2011-10-01 08:08:58.256000+00:00</td>\n",
       "      <td>2011-10-01 08:08:58.256000+00:00</td>\n",
       "      <td>173691</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>2011-10-01 08:09:02.195000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   org:resource lifecycle:transition            concept:name  \\\n",
       "0         112.0             COMPLETE             A_SUBMITTED   \n",
       "1         112.0             COMPLETE       A_PARTLYSUBMITTED   \n",
       "2         112.0             COMPLETE           A_PREACCEPTED   \n",
       "3         112.0             SCHEDULE  W_Completeren aanvraag   \n",
       "4         112.0             COMPLETE             A_SUBMITTED   \n",
       "\n",
       "                     time:timestamp                     case:REG_DATE  \\\n",
       "0  2011-10-01 00:38:44.546000+00:00  2011-10-01 00:38:44.546000+00:00   \n",
       "1  2011-10-01 00:38:44.880000+00:00  2011-10-01 00:38:44.546000+00:00   \n",
       "2  2011-10-01 00:39:37.906000+00:00  2011-10-01 00:38:44.546000+00:00   \n",
       "3  2011-10-01 00:39:38.875000+00:00  2011-10-01 00:38:44.546000+00:00   \n",
       "4  2011-10-01 08:08:58.256000+00:00  2011-10-01 08:08:58.256000+00:00   \n",
       "\n",
       "   case:concept:name  case:AMOUNT_REQ  position       next_concept:name  \\\n",
       "0             173688            20000         1       A_PARTLYSUBMITTED   \n",
       "1             173688            20000         2           A_PREACCEPTED   \n",
       "2             173688            20000         3  W_Completeren aanvraag   \n",
       "3             173688            20000         4  W_Completeren aanvraag   \n",
       "4             173691             5000         1       A_PARTLYSUBMITTED   \n",
       "\n",
       "                     next_timestamp  \n",
       "0  2011-10-01 00:38:44.880000+00:00  \n",
       "1  2011-10-01 00:39:37.906000+00:00  \n",
       "2  2011-10-01 00:39:38.875000+00:00  \n",
       "3  2011-10-01 11:36:46.437000+00:00  \n",
       "4  2011-10-01 08:09:02.195000+00:00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/preprocessed/BPI_Challenge_2012.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining what category each column fall into\n",
    "dropping_columns = ['time:timestamp', 'case:REG_DATE', 'case:concept:name', 'next_timestamp', 'org:resource', 'case:AMOUNT_REQ','lifecycle:transition']\n",
    "numerical_columns = ['position']\n",
    "categorical_columns = ['concept:name']\n",
    "target_column = 'next_concept:name'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the target column to category\n",
    "original_target = df[target_column].copy()\n",
    "df[target_column] = df[target_column].astype('category')\n",
    "df[target_column] = df[target_column].cat.codes\n",
    "\n",
    "# One-hot encoding of the categorical columns \n",
    "df = pd.get_dummies(df, columns=categorical_columns)\n",
    "\n",
    "# Columns that were one_hot_encoded\n",
    "one_hot_encoded_columns = [col for col in df.columns if (col not in numerical_columns) and (col != target_column) and (col not in dropping_columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset into train and test dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 262200\n",
      "Train size: 186785\n",
      "Test size: 37781\n",
      "Ratio: 0.8317599280389729\n",
      "Dropped cases in both sets: 888\n",
      "Dropped rows from dataset: 37634\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data\n",
    "train_df, test_df = split_data(df, ratio=0.8, report=True)\n",
    "X_train = train_df[numerical_columns + one_hot_encoded_columns]\n",
    "y_train = train_df[target_column]\n",
    "X_test = test_df[numerical_columns + one_hot_encoded_columns]\n",
    "y_test = test_df[target_column]\n",
    "\n",
    "# Getting the feature types for xgboost\n",
    "ft = ['q' if feature in numerical_columns else 'c' for feature in X_train.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DMatrix for training and testing\n",
    "train_dmatrix = xgb.DMatrix(X_train, y_train, feature_types=ft, enable_categorical=True)\n",
    "test_dmatrix = xgb.DMatrix(data=X_test, label=y_test, feature_types=ft, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create XGBoost parameters\n",
    "params = {\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'objective': 'multi:softmax',  # for multi-class classification\n",
    "    'num_class': len(df[target_column].unique()),  # number of classes\n",
    "    'eval_metric': 'merror' # evaluation metric\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the XGBoost model\n",
    "xgb_model = xgb.train(params, train_dmatrix, num_boost_round=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the result and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "predictions = xgb_model.predict(test_dmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the mapping with the orginal_target and encoded one\n",
    "mapping = dict(zip(df[target_column], original_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_first(X_test, index, ft):\n",
    "    single_instance = X_test.loc[index]\n",
    "    single_instance = single_instance.values.reshape(1, -1)\n",
    "    single_instance_dmatrix = xgb.DMatrix(data=single_instance, feature_names=list(X_test.columns), feature_types=ft, enable_categorical=True)\n",
    "    single_instance_prediction = xgb_model.predict(single_instance_dmatrix)\n",
    "    return single_instance_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "def get_first_position(X_test, last_event_array_position):\n",
    "    single_instance = X_test.iloc[last_event_array_position]\n",
    "    position = int(single_instance.iloc[0])\n",
    "    return position\n",
    "\n",
    "print(get_first_position(X_test, 45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes prediction and makes it into one hot encoded df\n",
    "def format_prediction(prediction, position, column_names):\n",
    "    temp_df = pd.DataFrame(False, index=[0], columns=column_names)\n",
    "    temp_df.insert(0, 'position', position, True)\n",
    "    temp_df['concept:name_'+prediction] = temp_df['concept:name_'+prediction].replace([False], [True])\n",
    "    return temp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next(df, ft):\n",
    "    single_instance = df.iloc[0]\n",
    "    single_instance = single_instance.values.reshape(1, -1)\n",
    "    single_instance_dmatrix = xgb.DMatrix(data=single_instance, feature_names=list(X_test.columns), feature_types=ft, enable_categorical=True)\n",
    "    single_instance_prediction = xgb_model.predict(single_instance_dmatrix)\n",
    "    return single_instance_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_pos_event(position, event):\n",
    "    hot_pre = 'concept:name_'\n",
    "    if hot_pre in event:\n",
    "        event = event.replace(hot_pre, '')\n",
    "    array = [position, event]\n",
    "    return array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_prefix(prefix, addon):\n",
    "    #print(addon)\n",
    "    prefix.append(addon)\n",
    "    return prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns name of column wiht true value\n",
    "#aka the event in that position\n",
    "def column_with_true_value(row):\n",
    "    for col in row.index:\n",
    "        if row[col] == True:\n",
    "            return col\n",
    "    return None  # Return None if no True value found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamin\\AppData\\Local\\Temp\\ipykernel_15832\\1825849430.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['case:concept:name'] = df.loc[X_test.index]['case:concept:name']\n"
     ]
    }
   ],
   "source": [
    "# estabishing case concept name index dictionary\n",
    "X_test['case:concept:name'] = df.loc[X_test.index]['case:concept:name']\n",
    "case_dict = {}\n",
    "\n",
    "for case in X_test['case:concept:name'].unique():\n",
    "    case_dict[case] = X_test[X_test[\"case:concept:name\"] == case].index\n",
    "\n",
    "X_test = X_test.drop(columns='case:concept:name')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create fucntion to find and create an array of indexes to a certain trace\n",
    "#input case:concept:name of a trace\n",
    "#output array of indexes of all event belonging to that trace in order\n",
    "\n",
    "def find_trace_index_array(caseconceptname, position):\n",
    "    return case_dict[caseconceptname][position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_levensthein_distance(predicted, actual):\n",
    "    \"\"\"\n",
    "    calculating the distance between the two lists of activities\n",
    "    :param predicted: list of activities\n",
    "    :param actual: list of activities\n",
    "    :return: distance between the two lists\n",
    "    \"\"\"\n",
    "\n",
    "    # if the actual list is empty, return the length of the predicted list\n",
    "    if len(actual) == 0:\n",
    "        return len(predicted)\n",
    "\n",
    "    # if the predicted list is empty, return the length of the actual list\n",
    "    if len(predicted) == 0:\n",
    "        return len(actual)\n",
    "\n",
    "    # creating a matrix with the size of the two lists\n",
    "    matrix = [[0 for _ in range(len(actual) + 1)] for _ in range(len(predicted) + 1)]\n",
    "\n",
    "    # filling the first row and the first column of the matrix\n",
    "    for i in range(len(predicted) + 1):\n",
    "        matrix[i][0] = i\n",
    "    for j in range(len(actual) + 1):\n",
    "        matrix[0][j] = j\n",
    "\n",
    "    # filling the matrix\n",
    "    for i in range(1, len(predicted) + 1):\n",
    "        for j in range(1, len(actual) + 1):\n",
    "            if predicted[i - 1] == actual[j - 1]:\n",
    "                matrix[i][j] = matrix[i - 1][j - 1]\n",
    "            else:\n",
    "                matrix[i][j] = min(matrix[i - 1][j] + 1, matrix[i][j - 1] + 1, matrix[i - 1][j - 1] + 1)\n",
    "\n",
    "    return matrix[len(predicted)][len(actual)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2123 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2123/2123 [01:31<00:00, 23.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.8973151201130474"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "summ = 0\n",
    "counter = 0\n",
    "length = 0\n",
    "maxx = 0\n",
    "for case in tqdm(case_dict.keys()):\n",
    "    trace = case\n",
    "    trace_position = 0\n",
    "    prefix = []\n",
    "    actual_suffix = []\n",
    "    predicted_suffix = []\n",
    "    for i in range(1, 100):\n",
    "        index = find_trace_index_array(trace, trace_position)\n",
    "        if i == 1:\n",
    "            prefixevent = column_with_true_value(X_test.loc[index])\n",
    "            new_entry = combine_pos_event(trace_position, prefixevent)\n",
    "            prefix = update_prefix(prefix, new_entry)\n",
    "            prediction = mapping[predict_first(X_test, index, ft)[0]]\n",
    "            trace_position += 1\n",
    "        else:\n",
    "            new_entry = combine_pos_event(trace_position, prediction)\n",
    "            prefix = update_prefix(prefix, new_entry)\n",
    "            prediction = mapping[predict_next(df_prediction, ft)[0]]\n",
    "            trace_position += 1\n",
    "        actual_suffix.append(mapping[y_test.loc[index]])\n",
    "        predicted_suffix.append(prediction)\n",
    "        if mapping[y_test.loc[index]] == 'No_Activity':\n",
    "            break\n",
    "\n",
    "        if prediction == 'No_Activity':\n",
    "            break\n",
    "\n",
    "        df_prediction = format_prediction(prediction, trace_position, one_hot_encoded_columns)\n",
    "    if len(actual_suffix) > maxx:\n",
    "        maxx = len(actual_suffix)\n",
    "    summ += compute_levensthein_distance(actual_suffix, predicted_suffix)\n",
    "    counter += 1\n",
    "    length += len(actual_suffix)\n",
    "summ/counter\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8983050847457625"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting single case\n",
    "trace = 207882\n",
    "trace_position = 0\n",
    "prefix = []\n",
    "actual_suffix = []\n",
    "predicted_suffix = []\n",
    "for i in range(1, 100):\n",
    "    index = find_trace_index_array(trace, trace_position)\n",
    "    if i == 1:\n",
    "        prefixevent = column_with_true_value(X_test.loc[index])\n",
    "        new_entry = combine_pos_event(trace_position, prefixevent)\n",
    "        prefix = update_prefix(prefix, new_entry)\n",
    "        prediction = mapping[predict_first(X_test, index, ft)[0]]\n",
    "        trace_position += 1\n",
    "    else:\n",
    "        new_entry = combine_pos_event(trace_position, prediction)\n",
    "        prefix = update_prefix(prefix, new_entry)\n",
    "        prediction = mapping[predict_next(df_prediction, ft)[0]]\n",
    "        trace_position += 1\n",
    "    actual_suffix.append(mapping[y_test.loc[index]])\n",
    "    predicted_suffix.append(prediction)\n",
    "    if mapping[y_test.loc[index]] == 'No_Activity':\n",
    "        break\n",
    "\n",
    "    if prediction == 'No_Activity':\n",
    "        break\n",
    "\n",
    "    df_prediction = format_prediction(prediction, trace_position, one_hot_encoded_columns)\n",
    "if len(actual_suffix) > maxx:\n",
    "    maxx = len(actual_suffix)\n",
    "summ += compute_levensthein_distance(actual_suffix, predicted_suffix)\n",
    "counter += 1\n",
    "length += len(actual_suffix)\n",
    "summ/counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: A_PARTLYSUBMITTED,\n",
      "Actual: A_PARTLYSUBMITTED\n"
     ]
    }
   ],
   "source": [
    "# find the mapping with the orginal_target and encoded one\n",
    "mapping = dict(zip(df[target_column], original_target))\n",
    "# predicting a single instance \n",
    "trace = 207870\n",
    "trace_position = 0\n",
    "index = find_trace_index_array(trace, trace_position)\n",
    "xtest_case = X_test.loc[index].copy()\n",
    "\n",
    "single_instance = X_test.loc[index].values.reshape(1, -1)\n",
    "single_instance_dmatrix = xgb.DMatrix(data=single_instance, feature_names=list(X_test.columns), feature_types=ft, enable_categorical=True)\n",
    "single_instance_prediction = xgb_model.predict(single_instance_dmatrix)\n",
    "# Finding the mapping of the prediction to the actual value\n",
    "print(f'Prediction: {mapping[single_instance_prediction[0]]},\\nActual: {mapping[y_test.loc[index]]}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
